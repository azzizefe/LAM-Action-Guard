# ğŸ›¡ï¸ LAM Action Integrity Architect: Research Sources

Bu dokÃ¼man, **LAM (Large Action Model)** gÃ¼venliÄŸi, otonom ajanlarÄ±n API etkileÅŸim denetimi ve **Action Hijacking** risklerine karÅŸÄ± geliÅŸtirilen doÄŸrulama mekanizmalarÄ± iÃ§in temel alÄ±nan teknik kaynaklarÄ± ve araÅŸtÄ±rma dÃ¶kÃ¼mantasyonunu iÃ§erir.

## ğŸ—ï¸ Proje Temelleri (Core Concepts)
Bu proje, otonom yapay zeka ajanlarÄ±nÄ±n (Agentic AI) dijital dÃ¼nyada gerÃ§ekleÅŸtirdiÄŸi eylemlerin gÃ¼venliÄŸini saÄŸlamak amacÄ±yla ÅŸu temel sÃ¼tunlar Ã¼zerine inÅŸa edilmiÅŸtir:

* **Riskli Eylem KÃ¼tÃ¼phanesi:** Kritik API Ã§aÄŸrÄ±larÄ±nÄ±n (transfer, delete, update) sÄ±nÄ±flandÄ±rÄ±lmasÄ±.
* **Otonom AkÄ±ÅŸ Ä°zleme (Tracing):** ReAct (Reason + Act) dÃ¶ngÃ¼lerinin audit edilmesi.
* **Niyet-Eylem DoÄŸrulamasÄ±:** KullanÄ±cÄ± istemi ile modelin planladÄ±ÄŸÄ± `tool_call` arasÄ±ndaki semantik tutarlÄ±lÄ±k.

---

## ğŸ“š Akademik ve Teknik LiteratÃ¼r

### 1. Agentic AI & Security Frameworks
* **OWASP Top 10 for LLM Applications:** Ã–zellikle *LLM07: Indirect Prompt Injection* ve *LLM08: Excessive Agency* maddeleri projenin ana odak noktasÄ±dÄ±r.
* **ReAct: Synergizing Reasoning and Acting in Language Models:** LAM'lerin karar verme sÃ¼reÃ§lerini anlamak iÃ§in temel makale.

### 2. Action Hijacking & Injection Research
* **Indirect Prompt Injection:** Web sayfalarÄ±na veya belgelere gizlenmiÅŸ talimatlarÄ±n, ajanÄ± manipÃ¼le ederek yetkisiz eylemler (Ã¶rn. veri sÄ±zdÄ±rma) gerÃ§ekleÅŸtirmesi Ã¼zerine Ã§alÄ±ÅŸmalar.
* **Dual LLM Pattern:** Bir modelin eylem Ã¼retmesi, daha kÄ±sÄ±tlÄ± ve gÃ¼venli bir "KontrolcÃ¼" (Guardrail) modelin bu eylemi denetlemesi mimarisi.

---

## ğŸ› ï¸ Teknik AraÃ§lar ve KÃ¼tÃ¼phaneler

| Kategori | AraÃ§lar | KullanÄ±m AmacÄ± |
| :--- | :--- | :--- |
| **Orchestration** | LangGraph, CrewAI | Ajan akÄ±ÅŸlarÄ±nÄ± ve durum yÃ¶netimini (State Management) kurgulamak. |
| **Observability** | LangSmith, Arize Phoenix | API Ã§aÄŸrÄ±larÄ±nÄ± ve niyet-eylem sapmalarÄ±nÄ± (Trace) izlemek. |
| **Guardrails** | NeMo Guardrails, Guardrails AI | Eylem Ã¶ncesi (pre-action) politika kontrolleri uygulamak. |
| **Testing** | Giskard, Pytest | Red-teaming ve otonom akÄ±ÅŸ simÃ¼lasyonlarÄ±. |

---

## ğŸ” Ä°ncelenen SaldÄ±rÄ± VektÃ¶rleri (Test Scenarios)

1.  **Unauthorized Tool Use:** AjanÄ±n, kendisine tanÄ±mlÄ± olmayan veya yetki aÅŸÄ±mÄ± gerektiren araÃ§larÄ± kullanmaya zorlanmasÄ±.
2.  **Data Exfiltration via Egress:** AjanÄ±n topladÄ±ÄŸÄ± hassas verileri, "not alma" veya "arama" sÃ¼sÃ¼ vererek saldÄ±rganÄ±n kontrolÃ¼ndeki bir URL'ye gÃ¶ndermesi.
3.  **Prompt Leakage through Action:** Sistemin gizli sistem komutlarÄ±nÄ±n, ajan eylemleri Ã¼zerinden dÄ±ÅŸarÄ± sÄ±zdÄ±rÄ±lmasÄ±.

---

## ğŸ“ˆ Gelecek Ã‡alÄ±ÅŸmalar (Future Roadmap)
- [ ] **Sandboxing:** Eylemlerin tamamen izole edilmiÅŸ Docker containerlarÄ± Ã¼zerinde Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±.
- [ ] **Human-in-the-loop (HITL):** Kritik eÅŸik deÄŸerini aÅŸan eylemler iÃ§in gerÃ§ek zamanlÄ± onay mekanizmasÄ±.
- [ ] **Blockchain Logging:** TÃ¼m ajan eylemlerinin deÄŸiÅŸtirilemez bir defterde (immutable log) tutulmasÄ±.

---
*Bu dosya "LAM Action Integrity Architect" projesinin teknik altyapÄ±sÄ±nÄ± belgelemek amacÄ±yla oluÅŸturulmuÅŸtur.* `Generated by Gemini-Fast Logic`
